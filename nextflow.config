/*
 * -------------------------------------------------
 *  nfcore/rnaseq Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

manifest {
  name = '@git_repo_name@'
  description = '@ap_pipeline_description@'
  homePage = '@git_url@'
  author = 'Institut Curie - Bioinformatics core facility'
  version = '@git_commit@'
  mainScript = 'main.nf'
  nextflowVersion = '>=19.10.0'
}


/*
 * Configs and profiles
 */


// Additional configs
includeConfig 'conf/base.config'
includeConfig 'conf/genomes.config'
includeConfig 'conf/tools.config'


// Profiles
profiles {
  conda {
    includeConfig 'conf/conda.config'
  }
  multiconda {
    includeConfig 'conf/multiconda.config'
  }
  docker { 
    includeConfig 'conf/docker.config'
  }
  singularity { 
    includeConfig 'conf/singularity.config'
  }
  path {
    includeConfig 'conf/path.config'
  }
  cluster {
    includeConfig 'conf/cluster.config'
  }
  standard {
    includeConfig 'conf/standard.config'
  }
  test {
    includeConfig 'conf/test.config'
  }
  test_gitlab {
    includeConfig 'conf/test_gitlab.config'
  }
  test_local {
    includeConfig 'conf/test_local.config'
  }
  test_sarek {
    includeConfig 'conf/test_sarek.config'
  }
}

//TODO: Duplicate code (cf process.config)
// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// From nf-core
timeline {
  enabled = true
  file = "${params.summaryDir}/trace/timeline.html"
}
report {
  enabled = true
  file = "${params.summaryDir}/trace/report.html"
}
trace {
  enabled = true
  raw = true
  fields = 'process,task_id,hash,native_id,module,container,tag,name,status,exit,submit,start,complete,duration,realtime,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes,attempt,workdir,scratch,queue,cpus,memory,disk,time,env'
  file = "${params.summaryDir}/trace/trace.txt"
}
dag {
  enabled = true
  file = "${params.summaryDir}/trace/DAG.pdf"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def checkMax(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.maxMemory as nextflow.util.MemoryUnit) == 1)
        return params.maxMemory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.maxMemory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.maxTime as nextflow.util.Duration) == 1)
        return params.maxTime as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.maxTime}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.maxCpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.maxCpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
// Return the minimum between requirements and a maximum limit to ensure that resource requirements don't go over
def check_resource(obj) {
    try {
      if (obj.getClass() == nextflow.util.MemoryUnit && obj.compareTo(params.maxMemory as nextflow.util.MemoryUnit) == 1)
        return params.maxMemory as nextflow.util.MemoryUnit
      else if (obj.getClass() == nextflow.util.Duration && obj.compareTo(params.maxTime as nextflow.util.Duration) == 1)
        return params.maxTime as nextflow.util.Duration
      else if (obj.getClass() == java.lang.Integer)
        return Math.min(obj, params.maxCpus as int)
      else
        return obj
    } catch (all) {
        println "   ### ERROR ###   Max params max_memory:'${params.maxMemory}', max_time:'${params.maxTime}' or max_cpus:'${params.maxCpus}'  is not valid! Using default value: $obj"
    }
}


